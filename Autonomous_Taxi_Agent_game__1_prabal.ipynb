{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOMzVLlsu52sW2UggKK4xN6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabal5ghosh/Autonomous-Taxi-Agent-game-using-Q-learning-SARSA-and-Deep-Q-learning/blob/main/Autonomous_Taxi_Agent_game__1_prabal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1."
      ],
      "metadata": {
        "id": "Ij_kZDoNcdK7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "2v2Zzj86gqu9",
        "outputId": "54d65448-d224-49ec-aacf-f84ab76ad879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose algorithm (q_learning, sarsa, dqn): dqn\n",
            "Training DQN agent...\n",
            "Episode 0, Total Reward: -46\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DQN Evaluation Mean Reward: -10.00\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# For DQN (Deep Q-Learning)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "###############################\n",
        "# Q-LEARNING IMPLEMENTATION\n",
        "###############################\n",
        "def train_q_learning(env, num_episodes=100, max_steps=10, alpha=0.1, gamma=0.99,\n",
        "                     epsilon=1.0, min_epsilon=0.01, decay_rate=0.001):\n",
        "    Q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "    rewards_all_episodes = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        # The change is here: handle cases where env.reset() returns int or tuple\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result\n",
        "\n",
        "        total_reward = 0\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            # Epsilon-greedy action selection\n",
        "            if np.random.uniform(0, 1) < epsilon:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                action = np.argmax(Q_table[state, :])\n",
        "\n",
        "            # The change is here: handle cases where env.step() returns 4 or 5 values\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False  # Assuming truncated is not relevant in this case\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "            #done = terminated or truncated  # This line is now redundant\n",
        "\n",
        "            # Q-learning update: using max over next state's actions\n",
        "            Q_table[state, action] = (1 - alpha) * Q_table[state, action] + \\\n",
        "                                     alpha * (reward + gamma * np.max(Q_table[next_state, :]))\n",
        "\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            if terminated or truncated: #Change here to check for either termination or truncation\n",
        "                break\n",
        "\n",
        "        rewards_all_episodes.append(total_reward)\n",
        "        # Decay epsilon after each episode\n",
        "        epsilon = min_epsilon + (1.0 - min_epsilon) * np.exp(-decay_rate * episode)\n",
        "\n",
        "    return Q_table, rewards_all_episodes\n",
        "\n",
        "\n",
        "\n",
        "def train_sarsa(env, num_episodes=100, max_steps=10, alpha=0.1, gamma=0.99,\n",
        "                epsilon=1.0, min_epsilon=0.01, decay_rate=0.001):\n",
        "    Q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "    rewards_all_episodes = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        # The change is here: handle cases where env.reset() returns int or tuple\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result  # Handle the usual case with a tuple\n",
        "\n",
        "        total_reward = 0\n",
        "\n",
        "        # Choose initial action with epsilon-greedy\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(Q_table[state, :])\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            # The change is here: handle cases where env.step() returns 4 or 5 values\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False  # Assuming truncated is not relevant in this case\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "            done = terminated or truncated\n",
        "\n",
        "            # Choose next action using epsilon-greedy\n",
        "            if np.random.uniform(0, 1) < epsilon:\n",
        "                next_action = env.action_space.sample()\n",
        "            else:\n",
        "                next_action = np.argmax(Q_table[next_state, :])\n",
        "\n",
        "            # SARSA update rule\n",
        "            Q_table[state, action] += alpha * (reward + gamma * Q_table[next_state, next_action] - Q_table[state, action])\n",
        "\n",
        "            state = next_state\n",
        "            action = next_action\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        rewards_all_episodes.append(total_reward)\n",
        "        # Decay epsilon after each episode\n",
        "        epsilon = min_epsilon + (1.0 - min_epsilon) * np.exp(-decay_rate * episode)\n",
        "\n",
        "    return Q_table, rewards_all_episodes\n",
        "\n",
        "###############################\n",
        "# DQN (Deep Q-Learning) IMPLEMENTATION\n",
        "###############################\n",
        "\n",
        "# Define a simple neural network to approximate Q-values.\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.out = nn.Linear(64, action_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.out(x)\n",
        "\n",
        "# Replay Memory to store experience tuples\n",
        "class ReplayMemory:\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "def one_hot(state, state_size):\n",
        "    vec = np.zeros(state_size)\n",
        "    vec[state] = 1.0\n",
        "    return vec\n",
        "\n",
        "def train_dqn(env, num_episodes=100, max_steps=10, gamma=0.99,\n",
        "              epsilon=1.0, min_epsilon=0.1, decay_rate=0.001, lr=0.001,\n",
        "              batch_size=64, memory_capacity=10000, target_update=10):\n",
        "    state_size = env.observation_space.n\n",
        "    action_size = env.action_space.n\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    policy_net = DQN(state_size, action_size).to(device)\n",
        "    target_net = DQN(state_size, action_size).to(device)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "    target_net.eval()\n",
        "\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "    memory = ReplayMemory(memory_capacity)\n",
        "    rewards_all_episodes = []\n",
        "    steps_done = 0\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        # The change is here: handle cases where env.reset() returns int or tuple\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result\n",
        "\n",
        "        state_vec = one_hot(state, state_size)\n",
        "        total_reward = 0\n",
        "\n",
        "        for t in range(max_steps):\n",
        "            # Epsilon-greedy action selection\n",
        "            eps_threshold = min_epsilon + (epsilon - min_epsilon) * np.exp(-decay_rate * steps_done)\n",
        "            steps_done += 1\n",
        "            if random.random() < eps_threshold:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    state_tensor = torch.FloatTensor(state_vec).unsqueeze(0).to(device)\n",
        "                    q_values = policy_net(state_tensor)\n",
        "                    action = q_values.argmax().item()\n",
        "\n",
        "            # The change is here: handle cases where env.step() returns 4 or 5 values\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False  # Assuming truncated is not relevant in this case\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "            done = terminated or truncated\n",
        "\n",
        "            next_state_vec = one_hot(next_state, state_size)\n",
        "            memory.push(state_vec, action, reward, next_state_vec, done)\n",
        "            state_vec = next_state_vec\n",
        "            total_reward += reward\n",
        "\n",
        "            # Learn only if enough samples have been collected\n",
        "            if len(memory) >= batch_size:\n",
        "                batch = memory.sample(batch_size)\n",
        "                batch_state, batch_action, batch_reward, batch_next_state, batch_done = zip(*batch)\n",
        "\n",
        "                batch_state = torch.FloatTensor(batch_state).to(device)\n",
        "                batch_action = torch.LongTensor(batch_action).unsqueeze(1).to(device)\n",
        "                batch_reward = torch.FloatTensor(batch_reward).unsqueeze(1).to(device)\n",
        "                batch_next_state = torch.FloatTensor(batch_next_state).to(device)\n",
        "                batch_done = torch.FloatTensor(batch_done).unsqueeze(1).to(device)\n",
        "\n",
        "                current_q = policy_net(batch_state).gather(1, batch_action)\n",
        "                next_q = target_net(batch_next_state).max(1)[0].unsqueeze(1).detach()\n",
        "                expected_q = batch_reward + (gamma * next_q * (1 - batch_done))\n",
        "\n",
        "                loss = nn.MSELoss()(current_q, expected_q)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        rewards_all_episodes.append(total_reward)\n",
        "        # Update target network periodically\n",
        "        if episode % target_update == 0:\n",
        "            target_net.load_state_dict(policy_net.state_dict())\n",
        "        if episode % 100 == 0:\n",
        "            print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
        "\n",
        "    return policy_net, rewards_all_episodes\n",
        "\n",
        "###############################\n",
        "# EVALUATION FUNCTIONS\n",
        "###############################\n",
        "def evaluate_policy(env, Q_table, num_episodes=100, max_steps=10):\n",
        "    total_rewards = []\n",
        "    for episode in range(num_episodes):\n",
        "        # The change is here to handle cases where env.reset() returns int or tuple\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result  # Handle the usual case with a tuple\n",
        "\n",
        "        episode_reward = 0\n",
        "        for t in range(max_steps):\n",
        "            action = np.argmax(Q_table[state, :])\n",
        "            # The change is here: handling different return values from env.step()\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "\n",
        "            episode_reward += reward\n",
        "            state = next_state\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "        total_rewards.append(episode_reward)\n",
        "    mean_reward = np.mean(total_rewards)\n",
        "    return mean_reward\n",
        "\n",
        "def evaluate_dqn(env, policy_net, num_episodes=100, max_steps=10):\n",
        "    state_size = env.observation_space.n\n",
        "    total_rewards = []\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    for episode in range(num_episodes):\n",
        "        # The change is here to handle cases where env.reset() returns int or tuple\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result  # Handle the usual case with a tuple\n",
        "\n",
        "        state_vec = one_hot(state, state_size)\n",
        "        episode_reward = 0\n",
        "        for t in range(max_steps):\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.FloatTensor(state_vec).unsqueeze(0).to(device)\n",
        "                q_values = policy_net(state_tensor)\n",
        "                action = q_values.argmax().item()\n",
        "\n",
        "            # The change is here: handle cases where env.step() returns 4 or 5 values\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False  # Assuming truncated is not relevant in this case\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "            done = terminated or truncated\n",
        "\n",
        "            episode_reward += reward\n",
        "            state_vec = one_hot(next_state, state_size)\n",
        "            if done:\n",
        "                break\n",
        "        total_rewards.append(episode_reward)\n",
        "    mean_reward = np.mean(total_rewards)\n",
        "    return mean_reward\n",
        "\n",
        "###############################\n",
        "# MAIN FUNCTION\n",
        "###############################\n",
        "\n",
        "def main():\n",
        "    # Create the Taxi-v3 environment with RGB rendering (for consistency with Gym v0.26+)\n",
        "    env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n",
        "\n",
        "    algorithm = input(\"Choose algorithm (q_learning, sarsa, dqn): \").strip().lower()\n",
        "\n",
        "    if algorithm == \"q_learning\":\n",
        "        print(\"Training Q-learning agent...\")\n",
        "        Q_table, rewards = train_q_learning(env)\n",
        "        plt.plot(rewards)\n",
        "        plt.title(\"Q-learning Training Rewards\")\n",
        "        plt.xlabel(\"Episode\")\n",
        "        plt.ylabel(\"Total Reward\")\n",
        "        plt.show()\n",
        "        mean_reward = evaluate_policy(env, Q_table)\n",
        "        print(f\"Q-learning Evaluation Mean Reward: {mean_reward:.2f}\")\n",
        "\n",
        "    elif algorithm == \"sarsa\":\n",
        "        print(\"Training SARSA agent...\")\n",
        "        Q_table, rewards = train_sarsa(env)\n",
        "        plt.plot(rewards)\n",
        "        plt.title(\"SARSA Training Rewards\")\n",
        "        plt.xlabel(\"Episode\")\n",
        "        plt.ylabel(\"Total Reward\")\n",
        "        plt.show()\n",
        "        mean_reward = evaluate_policy(env, Q_table)\n",
        "        print(f\"SARSA Evaluation Mean Reward: {mean_reward:.2f}\")\n",
        "\n",
        "    elif algorithm == \"dqn\":\n",
        "        print(\"Training DQN agent...\")\n",
        "        policy_net, rewards = train_dqn(env)\n",
        "        plt.plot(rewards)\n",
        "        plt.title(\"DQN Training Rewards\")\n",
        "        plt.xlabel(\"Episode\")\n",
        "        plt.ylabel(\"Total Reward\")\n",
        "        plt.show()\n",
        "        mean_reward = evaluate_dqn(env, policy_net)\n",
        "        print(f\"DQN Evaluation Mean Reward: {mean_reward:.2f}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Unknown algorithm selected.\")\n",
        "\n",
        "    env.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QupwgkHjgxJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sifpUQ9Sa2lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qqjNOywUa2iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2."
      ],
      "metadata": {
        "id": "0fx2EskTa2N0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "je4CqDWIa3SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T1dyMKkQa3O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gzQEQ0loa3L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# For DQN (Deep Q-Learning)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "###############################\n",
        "# Q-LEARNING IMPLEMENTATION\n",
        "###############################\n",
        "def train_q_learning(env, num_episodes=10000, max_steps=100, alpha=0.1, gamma=0.99,\n",
        "                     epsilon=1.0, min_epsilon=0.01, decay_rate=0.001):\n",
        "    Q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "    rewards_all_episodes = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result\n",
        "\n",
        "        total_reward = 0\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            if np.random.uniform(0, 1) < epsilon:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                action = np.argmax(Q_table[state, :])\n",
        "\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "\n",
        "            Q_table[state, action] = (1 - alpha) * Q_table[state, action] + \\\n",
        "                                     alpha * (reward + gamma * np.max(Q_table[next_state, :]))\n",
        "\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "        rewards_all_episodes.append(total_reward)\n",
        "        epsilon = min_epsilon + (1.0 - min_epsilon) * np.exp(-decay_rate * episode)\n",
        "\n",
        "    return Q_table, rewards_all_episodes\n",
        "\n",
        "###############################\n",
        "# SARSA IMPLEMENTATION\n",
        "###############################\n",
        "def train_sarsa(env, num_episodes=10000, max_steps=100, alpha=0.1, gamma=0.99,\n",
        "                epsilon=1.0, min_epsilon=0.01, decay_rate=0.001):\n",
        "    Q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "    rewards_all_episodes = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result\n",
        "\n",
        "        total_reward = 0\n",
        "\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(Q_table[state, :])\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "            done = terminated or truncated\n",
        "\n",
        "            if np.random.uniform(0, 1) < epsilon:\n",
        "                next_action = env.action_space.sample()\n",
        "            else:\n",
        "                next_action = np.argmax(Q_table[next_state, :])\n",
        "\n",
        "            Q_table[state, action] += alpha * (reward + gamma * Q_table[next_state, next_action] - Q_table[state, action])\n",
        "\n",
        "            state = next_state\n",
        "            action = next_action\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        rewards_all_episodes.append(total_reward)\n",
        "        epsilon = min_epsilon + (1.0 - min_epsilon) * np.exp(-decay_rate * episode)\n",
        "\n",
        "    return Q_table, rewards_all_episodes\n",
        "\n",
        "###############################\n",
        "# DQN (Deep Q-Learning) IMPLEMENTATION\n",
        "###############################\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.out = nn.Linear(64, action_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.out(x)\n",
        "\n",
        "class ReplayMemory:\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "def one_hot(state, state_size):\n",
        "    vec = np.zeros(state_size)\n",
        "    vec[state] = 1.0\n",
        "    return vec\n",
        "\n",
        "def train_dqn(env, num_episodes=10000, max_steps=100, gamma=0.99,\n",
        "              epsilon=1.0, min_epsilon=0.1, decay_rate=0.001, lr=0.001,\n",
        "              batch_size=64, memory_capacity=10000, target_update=10):\n",
        "    state_size = env.observation_space.n\n",
        "    action_size = env.action_space.n\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    policy_net = DQN(state_size, action_size).to(device)\n",
        "    target_net = DQN(state_size, action_size).to(device)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "    target_net.eval()\n",
        "\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "    memory = ReplayMemory(memory_capacity)\n",
        "    rewards_all_episodes = []\n",
        "    steps_done = 0\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result\n",
        "\n",
        "        state_vec = one_hot(state, state_size)\n",
        "        total_reward = 0\n",
        "\n",
        "        for t in range(max_steps):\n",
        "            eps_threshold = min_epsilon + (epsilon - min_epsilon) * np.exp(-decay_rate * steps_done)\n",
        "            steps_done += 1\n",
        "            if random.random() < eps_threshold:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    state_tensor = torch.FloatTensor(state_vec).unsqueeze(0).to(device)\n",
        "                    q_values = policy_net(state_tensor)\n",
        "                    action = q_values.argmax().item()\n",
        "\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "            done = terminated or truncated\n",
        "\n",
        "            next_state_vec = one_hot(next_state, state_size)\n",
        "            memory.push(state_vec, action, reward, next_state_vec, done)\n",
        "            state_vec = next_state_vec\n",
        "            total_reward += reward\n",
        "\n",
        "            if len(memory) >= batch_size:\n",
        "                batch = memory.sample(batch_size)\n",
        "                batch_state, batch_action, batch_reward, batch_next_state, batch_done = zip(*batch)\n",
        "\n",
        "                batch_state = torch.FloatTensor(batch_state).to(device)\n",
        "                batch_action = torch.LongTensor(batch_action).unsqueeze(1).to(device)\n",
        "                batch_reward = torch.FloatTensor(batch_reward).unsqueeze(1).to(device)\n",
        "                batch_next_state = torch.FloatTensor(batch_next_state).to(device)\n",
        "                batch_done = torch.FloatTensor(batch_done).unsqueeze(1).to(device)\n",
        "\n",
        "                current_q = policy_net(batch_state).gather(1, batch_action)\n",
        "                next_q = target_net(batch_next_state).max(1)[0].unsqueeze(1).detach()\n",
        "                expected_q = batch_reward + (gamma * next_q * (1 - batch_done))\n",
        "\n",
        "                loss = nn.MSELoss()(current_q, expected_q)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        rewards_all_episodes.append(total_reward)\n",
        "        if episode % target_update == 0:\n",
        "            target_net.load_state_dict(policy_net.state_dict())\n",
        "        if episode % 100 == 0:\n",
        "            print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
        "\n",
        "    return policy_net, rewards_all_episodes\n",
        "\n",
        "###############################\n",
        "# EVALUATION FUNCTIONS\n",
        "###############################\n",
        "def evaluate_policy(env, Q_table, num_episodes=10000, max_steps=100):\n",
        "    total_rewards = []\n",
        "    for episode in range(num_episodes):\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result\n",
        "\n",
        "        episode_reward = 0\n",
        "        for t in range(max_steps):\n",
        "            action = np.argmax(Q_table[state, :])\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "\n",
        "            episode_reward += reward\n",
        "            state = next_state\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "        total_rewards.append(episode_reward)\n",
        "    mean_reward = np.mean(total_rewards)\n",
        "    return mean_reward\n",
        "\n",
        "def evaluate_dqn(env, policy_net, num_episodes=10000, max_steps=100):\n",
        "    state_size = env.observation_space.n\n",
        "    total_rewards = []\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    for episode in range(num_episodes):\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result\n",
        "\n",
        "        state_vec = one_hot(state, state_size)\n",
        "        episode_reward = 0\n",
        "        for t in range(max_steps):\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.FloatTensor(state_vec).unsqueeze(0).to(device)\n",
        "                q_values = policy_net(state_tensor)\n",
        "                action = q_values.argmax().item()\n",
        "\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "            done = terminated or truncated\n",
        "\n",
        "            episode_reward += reward\n",
        "            state_vec = one_hot(next_state, state_size)\n",
        "            if done:\n",
        "                break\n",
        "        total_rewards.append(episode_reward)\n",
        "    mean_reward = np.mean(total_rewards)\n",
        "    return mean_reward\n",
        "\n",
        "###############################\n",
        "# MAIN FUNCTION\n",
        "###############################\n",
        "def plot_rewards(rewards, title):\n",
        "    plt.plot(rewards)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Total Reward\")\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n",
        "\n",
        "    print(\"Training Q-learning agent...\")\n",
        "    Q_table_q_learning, rewards_q_learning = train_q_learning(env)\n",
        "    plot_rewards(rewards_q_learning, \"Q-learning Training Rewards\")\n",
        "    mean_reward_q_learning = evaluate_policy(env, Q_table_q_learning)\n",
        "    print(f\"Q-learning Evaluation Mean Reward: {mean_reward_q_learning:.2f}\")\n",
        "\n",
        "    print(\"Training SARSA agent...\")\n",
        "    Q_table_sarsa, rewards_sarsa = train_sarsa(env)\n",
        "    plot_rewards(rewards_sarsa, \"SARSA Training Rewards\")\n",
        "    mean_reward_sarsa = evaluate_policy(env, Q_table_sarsa)\n",
        "    print(f\"SARSA Evaluation Mean Reward: {mean_reward_sarsa:.2f}\")\n",
        "\n",
        "    print(\"Training DQN agent...\")\n",
        "    policy_net_dqn, rewards_dqn = train_dqn(env)\n",
        "    plot_rewards(rewards_dqn, \"DQN Training Rewards\")\n",
        "    mean_reward_dqn = evaluate_dqn(env, policy_net_dqn)\n",
        "    print(f\"DQN Evaluation Mean Reward: {mean_reward_dqn:.2f}\")\n",
        "\n",
        "    env.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "dBCrc_I7a3I_",
        "outputId": "49f421fa-53b5-45f8-a6ed-cdd78fa538d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Q-learning agent...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.animation as animation\n",
        "\n",
        "def animate_policy(env, Q_table, max_steps=10):\n",
        "    fig = plt.figure()\n",
        "    frames = []\n",
        "\n",
        "    reset_result = env.reset()\n",
        "    if isinstance(reset_result, int):\n",
        "        state = reset_result\n",
        "    else:\n",
        "        state, _ = reset_result\n",
        "\n",
        "    for t in range(max_steps):\n",
        "        action = np.argmax(Q_table[state, :])\n",
        "        step_result = env.step(action)\n",
        "        if len(step_result) == 4:\n",
        "            next_state, reward, done, _ = step_result\n",
        "            terminated = done\n",
        "            truncated = False\n",
        "        else:\n",
        "            next_state, reward, terminated, truncated, _ = step_result\n",
        "\n",
        "        img = env.render()\n",
        "        frames.append([plt.imshow(img, animated=True)])\n",
        "\n",
        "        state = next_state\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, frames, interval=200, blit=True, repeat_delay=1000)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# animate_policy(env, Q_table_q_learning)"
      ],
      "metadata": {
        "id": "M9cnJ2r5a3GK",
        "outputId": "deb733c0-299c-4331-9d4e-78c01a71ddc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'env' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-98ab3e7cd1a5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0manimate_dqn_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_net_dqn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfiK2EIIa3DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3."
      ],
      "metadata": {
        "id": "lEVAxtWYcMff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "# For DQN (Deep Q-Learning)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "###############################\n",
        "# Q-LEARNING IMPLEMENTATION\n",
        "###############################\n",
        "def train_q_learning(env, num_episodes=100, max_steps=10, alpha=0.1, gamma=0.99,\n",
        "                     epsilon=1.0, min_epsilon=0.01, decay_rate=0.001):\n",
        "    Q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "    rewards_all_episodes = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result\n",
        "\n",
        "        total_reward = 0\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            if np.random.uniform(0, 1) < epsilon:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                action = np.argmax(Q_table[state, :])\n",
        "\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "\n",
        "            Q_table[state, action] = (1 - alpha) * Q_table[state, action] + \\\n",
        "                                     alpha * (reward + gamma * np.max(Q_table[next_state, :]))\n",
        "\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "        rewards_all_episodes.append(total_reward)\n",
        "        epsilon = min_epsilon + (1.0 - min_epsilon) * np.exp(-decay_rate * episode)\n",
        "\n",
        "    return Q_table, rewards_all_episodes\n",
        "\n",
        "###############################\n",
        "# SARSA IMPLEMENTATION\n",
        "###############################\n",
        "def train_sarsa(env, num_episodes=100, max_steps=10, alpha=0.1, gamma=0.99,\n",
        "                epsilon=1.0, min_epsilon=0.01, decay_rate=0.001):\n",
        "    Q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "    rewards_all_episodes = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result\n",
        "\n",
        "        total_reward = 0\n",
        "\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(Q_table[state, :])\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "            done = terminated or truncated\n",
        "\n",
        "            if np.random.uniform(0, 1) < epsilon:\n",
        "                next_action = env.action_space.sample()\n",
        "            else:\n",
        "                next_action = np.argmax(Q_table[next_state, :])\n",
        "\n",
        "            Q_table[state, action] += alpha * (reward + gamma * Q_table[next_state, next_action] - Q_table[state, action])\n",
        "\n",
        "            state = next_state\n",
        "            action = next_action\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        rewards_all_episodes.append(total_reward)\n",
        "        epsilon = min_epsilon + (1.0 - min_epsilon) * np.exp(-decay_rate * episode)\n",
        "\n",
        "    return Q_table, rewards_all_episodes\n",
        "\n",
        "###############################\n",
        "# DQN (Deep Q-Learning) IMPLEMENTATION\n",
        "###############################\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.out = nn.Linear(64, action_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.out(x)\n",
        "\n",
        "class ReplayMemory:\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "def one_hot(state, state_size):\n",
        "    vec = np.zeros(state_size)\n",
        "    vec[state] = 1.0\n",
        "    return vec\n",
        "\n",
        "def train_dqn(env, num_episodes=100, max_steps=10, gamma=0.99,\n",
        "              epsilon=1.0, min_epsilon=0.1, decay_rate=0.001, lr=0.001,\n",
        "              batch_size=64, memory_capacity=10000, target_update=10):\n",
        "    state_size = env.observation_space.n\n",
        "    action_size = env.action_space.n\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    policy_net = DQN(state_size, action_size).to(device)\n",
        "    target_net = DQN(state_size, action_size).to(device)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "    target_net.eval()\n",
        "\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "    memory = ReplayMemory(memory_capacity)\n",
        "    rewards_all_episodes = []\n",
        "    steps_done = 0\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result\n",
        "\n",
        "        state_vec = one_hot(state, state_size)\n",
        "        total_reward = 0\n",
        "\n",
        "        for t in range(max_steps):\n",
        "            eps_threshold = min_epsilon + (epsilon - min_epsilon) * np.exp(-decay_rate * steps_done)\n",
        "            steps_done += 1\n",
        "            if random.random() < eps_threshold:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    state_tensor = torch.FloatTensor(state_vec).unsqueeze(0).to(device)\n",
        "                    q_values = policy_net(state_tensor)\n",
        "                    action = q_values.argmax().item()\n",
        "\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "            done = terminated or truncated\n",
        "\n",
        "            next_state_vec = one_hot(next_state, state_size)\n",
        "            memory.push(state_vec, action, reward, next_state_vec, done)\n",
        "            state_vec = next_state_vec\n",
        "            total_reward += reward\n",
        "\n",
        "            if len(memory) >= batch_size:\n",
        "                batch = memory.sample(batch_size)\n",
        "                batch_state, batch_action, batch_reward, batch_next_state, batch_done = zip(*batch)\n",
        "\n",
        "                batch_state = torch.FloatTensor(batch_state).to(device)\n",
        "                batch_action = torch.LongTensor(batch_action).unsqueeze(1).to(device)\n",
        "                batch_reward = torch.FloatTensor(batch_reward).unsqueeze(1).to(device)\n",
        "                batch_next_state = torch.FloatTensor(batch_next_state).to(device)\n",
        "                batch_done = torch.FloatTensor(batch_done).unsqueeze(1).to(device)\n",
        "\n",
        "                current_q = policy_net(batch_state).gather(1, batch_action)\n",
        "                next_q = target_net(batch_next_state).max(1)[0].unsqueeze(1).detach()\n",
        "                expected_q = batch_reward + (gamma * next_q * (1 - batch_done))\n",
        "\n",
        "                loss = nn.MSELoss()(current_q, expected_q)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        rewards_all_episodes.append(total_reward)\n",
        "        if episode % target_update == 0:\n",
        "            target_net.load_state_dict(policy_net.state_dict())\n",
        "        if episode % 100 == 0:\n",
        "            print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
        "\n",
        "    return policy_net, rewards_all_episodes\n",
        "\n",
        "###############################\n",
        "# EVALUATION FUNCTIONS\n",
        "###############################\n",
        "def evaluate_policy(env, Q_table, num_episodes=100, max_steps=10):\n",
        "    total_rewards = []\n",
        "    for episode in range(num_episodes):\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result\n",
        "\n",
        "        episode_reward = 0\n",
        "        for t in range(max_steps):\n",
        "            action = np.argmax(Q_table[state, :])\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "\n",
        "            episode_reward += reward\n",
        "            state = next_state\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "        total_rewards.append(episode_reward)\n",
        "    mean_reward = np.mean(total_rewards)\n",
        "    return mean_reward\n",
        "\n",
        "def evaluate_dqn(env, policy_net, num_episodes=100, max_steps=10):\n",
        "    state_size = env.observation_space.n\n",
        "    total_rewards = []\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    for episode in range(num_episodes):\n",
        "        reset_result = env.reset()\n",
        "        if isinstance(reset_result, int):\n",
        "            state = reset_result\n",
        "        else:\n",
        "            state, _ = reset_result\n",
        "\n",
        "        state_vec = one_hot(state, state_size)\n",
        "        episode_reward = 0\n",
        "        for t in range(max_steps):\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.FloatTensor(state_vec).unsqueeze(0).to(device)\n",
        "                q_values = policy_net(state_tensor)\n",
        "                action = q_values.argmax().item()\n",
        "\n",
        "            step_result = env.step(action)\n",
        "            if len(step_result) == 4:\n",
        "                next_state, reward, done, _ = step_result\n",
        "                terminated = done\n",
        "                truncated = False\n",
        "            else:\n",
        "                next_state, reward, terminated, truncated, _ = step_result\n",
        "            done = terminated or truncated\n",
        "\n",
        "            episode_reward += reward\n",
        "            state_vec = one_hot(next_state, state_size)\n",
        "            if done:\n",
        "                break\n",
        "        total_rewards.append(episode_reward)\n",
        "    mean_reward = np.mean(total_rewards)\n",
        "    return mean_reward\n",
        "\n",
        "###############################\n",
        "# ANIMATION FUNCTION\n",
        "###############################\n",
        "def animate_policy(env, Q_table, max_steps=10):\n",
        "    fig = plt.figure()\n",
        "    frames = []\n",
        "\n",
        "    reset_result = env.reset()\n",
        "    if isinstance(reset_result, int):\n",
        "        state = reset_result\n",
        "    else:\n",
        "        state, _ = reset_result\n",
        "\n",
        "    for t in range(max_steps):\n",
        "        action = np.argmax(Q_table[state, :])\n",
        "        step_result = env.step(action)\n",
        "        if len(step_result) == 4:\n",
        "            next_state, reward, done, _ = step_result\n",
        "            terminated = done\n",
        "            truncated = False\n",
        "        else:\n",
        "            next_state, reward, terminated, truncated, _ = step_result\n",
        "\n",
        "        img = env.render()\n",
        "        img = np.array(img)  # Convert to numpy array\n",
        "        frames.append([plt.imshow(img, animated=True)])\n",
        "\n",
        "        state = next_state\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, frames, interval=200, blit=True, repeat_delay=1000)\n",
        "    plt.show()\n",
        "\n",
        "###############################\n",
        "# MAIN FUNCTION\n",
        "###############################\n",
        "def plot_rewards(rewards, title):\n",
        "    plt.plot(rewards)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Total Reward\")\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n",
        "\n",
        "    print(\"Training Q-learning agent...\")\n",
        "    Q_table_q_learning, rewards_q_learning = train_q_learning(env)\n",
        "    plot_rewards(rewards_q_learning, \"Q-learning Training Rewards\")\n",
        "    mean_reward_q_learning = evaluate_policy(env, Q_table_q_learning)\n",
        "    print(f\"Q-learning Evaluation Mean Reward: {mean_reward_q_learning:.2f}\")\n",
        "\n",
        "    print(\"Training SARSA agent...\")\n",
        "    Q_table_sarsa, rewards_sarsa = train_sarsa(env)\n",
        "    plot_rewards(rewards_sarsa, \"SARSA Training Rewards\")\n",
        "    mean_reward_sarsa = evaluate_policy(env, Q_table_sarsa)\n",
        "    print(f\"SARSA Evaluation Mean Reward: {mean_reward_sarsa:.2f}\")\n",
        "\n",
        "    print(\"Training DQN agent...\")\n",
        "    policy_net_dqn, rewards_dqn = train_dqn(env)\n",
        "    plot_rewards(rewards_dqn, \"DQN Training Rewards\")\n",
        "    mean_reward_dqn = evaluate_dqn(env, policy_net_dqn)\n",
        "    print(f\"DQN Evaluation Mean Reward: {mean_reward_dqn:.2f}\")\n",
        "\n",
        "    print(\"Animating Q-learning agent...\")\n",
        "    animate_policy(env, Q_table_q_learning)\n",
        "\n",
        "    env.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Ia2bIYNscM7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8fLhfag-cNBy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}